{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from stix2.v21 import (ThreatActor, Identity, AttackPattern, Campaign, IntrusionSet, Relationship, ExternalReference, Bundle, Grouping)\n",
    "from efficient_apriori import apriori\n",
    "import re\n",
    "from pyattck import Attck\n",
    "import requests\n",
    "import json\n",
    "from stix2 import MemoryStore, Filter\n",
    "from neo4j import GraphDatabase\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings Values - for Apriori Algorithm\n",
    "# TODO - 2: Do we need to adjust these numbers, in order to refine our algorithm metrics??\n",
    "confidenceLevel = 0.71\n",
    "supportLevel = 0.05\n",
    "abstract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NameToCode(gName):\n",
    "    # create an instance of the Attck class\n",
    "    attck = Attck()\n",
    "\n",
    "    # get all APT groups in the framework\n",
    "    apt_groups = attck.enterprise.actors\n",
    "\n",
    "    # create a dictionary mapping APT group names to G codes\n",
    "    group_to_gcode = {}\n",
    "    for group in apt_groups:\n",
    "        if group.name == gName:\n",
    "            gcode = group.id\n",
    "            return gcode\n",
    "    return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateTestSet():\n",
    "    df = pd.read_csv(\"datasets/Categorized_Adversary_TTPs.csv\").loc[:, ['mitre_attack_name', 'mitre_attack_ttps']] # sample dataset of attacks\n",
    "    test_threat_profiles = {}\n",
    "    for row in df.values:\n",
    "        gcode = NameToCode(row[0].strip())\n",
    "        tcodes = (row[1].strip(\"'][\").replace(\"'\",\"\").split(', '))\n",
    "        if (len(tcodes) > 0):\n",
    "            test_threat_profiles[gcode] = tcodes\n",
    "    \n",
    "    return test_threat_profiles\n",
    "    \n",
    "def GenerateAprioriLists():\n",
    "\n",
    "    #Data from Scott at Tidal Cyber\n",
    "    ttpLists = []\n",
    "    df1 = json.load(open(\"datasets/TidalCyberData/otx_running.json\")) [1:]\n",
    "    for row in df1:\n",
    "        if len(row[7]) > 0 and type(row[7]) == type([]):\n",
    "            ttpLists.append([\"'\" + ttp + \"'\" for ttp in row[7]])\n",
    "    \n",
    "    df2 = json.load(open(\"datasets/TidalCyberData/Tidal OSINT Technique Extraction.json\"))\n",
    "    for row in df2:\n",
    "        if len(row['Tidal Extracted Techniques']) > 0:\n",
    "            ttpLists.append([\"'\" + ttp2 + \"'\" for ttp2 in row['Tidal Extracted Techniques']])\n",
    "    # Some data comes from this dataset with TTPs\n",
    "\n",
    "    # More data is gained by using attck data from tool and malware TTPs\n",
    "    attack = Attck()\n",
    "    \n",
    "    malwares = attack.enterprise.malwares + attack.enterprise.tools\n",
    "    \n",
    "    for malware in malwares:\n",
    "        ttpLists.append([\"'\" + ttp.id + \"'\" for ttp in malware.techniques])\n",
    "\n",
    "    # To use the apriori we need to generate a list of lists\n",
    "    aprList = ttpLists\n",
    "    # for row in df3.values:\n",
    "    #     aprList.append((row[13].strip('][').split(', ')))\n",
    "\n",
    "    # get rid of empty sets\n",
    "    return [ttp for ttp in aprList if len(ttp) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AbstractTTPs(ttpList):\n",
    "    # Take sub-techniques and remove the .### to abstract them to parent techniques \n",
    "    for i in range(0,len(ttpList)):\n",
    "        ttpList[i] = [re.sub(r'\\.[0-9]+', '', ttp) for ttp in ttpList[i]]\n",
    "    return ttpList "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a list of lists and returns a list of rules sorted by size \n",
    "def AprioriMining(aprList):\n",
    "    # Perform apriori rule association mining\n",
    "    itemsets, rules = apriori(aprList, min_support=supportLevel, min_confidence=confidenceLevel)\n",
    "    \n",
    "    # Sort by size to get the 1:1 mappings first and so on. \n",
    "    ruleNums = np.array([len(rule.lhs+rule.rhs) for rule in rules])\n",
    "    rules = np.array(rules)\n",
    "    inds = ruleNums.argsort()[::]\n",
    "    rules = rules[inds]\n",
    "    \n",
    "    # Maximum rule size of 4 to limit number of rules, any rules with size > 4 are redundant anyways\n",
    "    rules = [x for x in filter(lambda rule: len(rule.lhs+rule.rhs) <= 4, rules)]\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads latest MITRE framework from the branch\n",
    "def get_data_from_branch(domain):\n",
    "    \"\"\"get the ATT&CK STIX data from MITRE/CTI. Domain should be 'enterprise-attack', 'mobile-attack' or 'ics-attack'. Branch should typically be master.\"\"\"\n",
    "    stix_json = requests.get(f\"https://raw.githubusercontent.com/mitre-attack/attack-stix-data/master/{domain}/{domain}.json\").json()\n",
    "    return MemoryStore(stix_data=stix_json[\"objects\"])\n",
    "\n",
    "src = get_data_from_branch(\"enterprise-attack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TTPs from seed, where seed is an APT group code: GXXXX\n",
    "def ExtractSeedTTPs(seed):\n",
    "    seeds = []\n",
    "    # This runs but says that \"actors\" is not found\n",
    "    actor = actors[seed]\n",
    "    for ttp in actor.techniques:\n",
    "        seeds.append(ttp.id)\n",
    "        \n",
    "    # If we are using abstracted TTPs then remove sub technique\n",
    "    if (abstract):\n",
    "        for i in range(0, len(seeds)):\n",
    "            seeds[i] = re.sub(r'\\.[0-9]+', '', seeds[i])\n",
    "    return seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExportBundle(bundle, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(bundle.serialize())\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each rule has a confidence, lift, support, lhs, rhs, conviction, rule power factor (RPF), \n",
    "\n",
    "# dictionaries to optimize requests\n",
    "ttpDictionary = {}\n",
    "\n",
    "# Takes an APTGroup and generates hypothesized relationships and attack pattern objects\n",
    "# Returns a tuple of: (profile, attackPatterns, relationships, attackPatterns)\n",
    "def CreateRelationships(seeds, aprioriLists):\n",
    "    profile = {} #stores the TTP and tactic for easy logging\n",
    "    seen = [] #stores TTPs that have been seen by the algorithm\n",
    "    attackPatterns = {} #stores generated attack pattern objects\n",
    "    relationships = {} # stores generated relationship objects\n",
    "    # attackPatterns = {} # stores generated grouping objects\n",
    "\n",
    "    # Get seeds out of the APT group\n",
    "    # seeds = ExtractSeedTTPs(APTGroup)\n",
    "    # seeds = [\"T1566\", \"T1204\"]\n",
    "    \n",
    "    # Perform Association Rule Mining\n",
    "    rules = AprioriMining(aprioriLists) \n",
    "    \n",
    "    for seed in seeds:\n",
    "       ## print(seed)\n",
    "        profile[seed] = 1\n",
    "        ttp = 0\n",
    "        # Get the stix object for the TTP\n",
    "        if (not(seed in list(ttpDictionary.keys()))):\n",
    "            try:          \n",
    "                ttp = src.query([ Filter(\"external_references.external_id\", \"=\", seed) ])[0]\n",
    "                ttpDictionary[seed] = ttp\n",
    "            except:\n",
    "                continue\n",
    "        else:\n",
    "            ttp = ttpDictionary[seed]\n",
    "            \n",
    "        if (ttp != 0):\n",
    "        # Create and add objects to lists, context is used to identify seeds from hypothesized events\n",
    "            attackPatterns[seed] = ttp\n",
    "    \n",
    "    # print(profile)\n",
    "    \n",
    "    seedTotals = [\"'\"+x+\"'\" for x in seeds]\n",
    "    # Use a queue to iterate through and create a tree of TTPs\n",
    "    while len(seeds) > 0:\n",
    "        for rule in rules:\n",
    "            # Check to see if the left hand side of a rule is satisfied \n",
    "            if \"'\"+seeds[0]+\"'\" in rule.lhs and set(rule.lhs).issubset(seedTotals):\n",
    "                # If the lhs is satisfied, then loop through each TTP in the rhs \n",
    "                for ttpName in rule.rhs:\n",
    "                    # If this TTP hasn't been visited already then create STIX objects\n",
    "                    if ttpName not in seen:\n",
    "                        if (not(ttpName[1:-1] in ttpDictionary.keys())):\n",
    "                            ttp = src.query([ Filter(\"external_references.external_id\", \"=\", ttpName[1:-1]) ])[0]\n",
    "                            ttpDictionary[ttpName[1:-1]] = ttp\n",
    "                        else:\n",
    "                            ttp = ttpDictionary[ttpName[1:-1]]\n",
    "                        # rule tactics \n",
    "                        tactics = []\n",
    "                        for i in ttp['kill_chain_phases']:\n",
    "                            tactics.append(i['phase_name'])\n",
    "                        \n",
    "                        # create a new grouping object with the rule name. \n",
    "                        \n",
    "                        attackPatterns[ttpName[1:-1]] = ttp\n",
    "                        seedTotals.append(ttpName)\n",
    "                        seen.append(ttpName)\n",
    "                        seeds.append(ttp['external_references'][0]['external_id'])\n",
    "\n",
    "                    # if the relationship already exists between two objects then we take the one with higher confidence\n",
    "                    # make sure the exact relationship does not alraedy exist\n",
    "                    if not (attackPatterns[seeds[0]]['id'], attackPatterns[ttpName[1:-1]]['id']) in relationships:\n",
    "                        # if the opposite relationship exists then choose the one with the highest confidence to add\n",
    "                        # we do this because if we do not then on the graph there will be two arrows going opposite directions to connect the same 2 TTPs\n",
    "                        # this causes clutter and makes the confidence values unreadable since they will be layered on top of each other\n",
    "                        if (attackPatterns[ttpName[1:-1]]['id'], attackPatterns[seeds[0]]['id']) in relationships:\n",
    "                            # if existing relationship has higher confidence, move on\n",
    "                            if float(relationships[(attackPatterns[ttpName[1:-1]]['id'], attackPatterns[seeds[0]]['id'])]['relationship_type']) > rule.confidence:\n",
    "                                continue # move to next iteration of for loop, so code after this statement won't execute\n",
    "                            # if existing relationship has lower confidence, delete it and let the new relationship take it's place\n",
    "                            else:\n",
    "                                del relationships[(attackPatterns[ttpName[1:-1]]['id'], attackPatterns[seeds[0]]['id'])]\n",
    "                        relationships[(attackPatterns[seeds[0]]['id'], attackPatterns[ttpName[1:-1]]['id'])] = Relationship(attackPatterns[seeds[0]]['id'], str(round(rule.confidence, 3)), attackPatterns[ttpName[1:-1]]['id'])\n",
    "                        if not((ttpName[1:-1] in profile.keys() and profile[ttpName[1:-1]] >= 1)):\n",
    "                            profile[ttpName[1:-1]] = round(rule.confidence, 3)\n",
    " \n",
    "        # pop to progress the queue\n",
    "        seeds.pop(0) \n",
    "    \n",
    "    for seed in seeds:\n",
    "        profile[seed] = 1\n",
    "        \n",
    "\n",
    "    return (profile, attackPatterns, relationships)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1199"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aprioriList = AbstractTTPs(GenerateAprioriLists()) # generate lists for apriori\n",
    "len(aprioriList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "intelSeed = [\"T1566\", \"T1204\"] # Use-case: Observed TTPs\n",
    "profile, attackPatterns, relationships = CreateRelationships(intelSeed, aprioriList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Displays the results of the Apiori Algorithm \n",
    "print(relationships)\n",
    "\n",
    "# This is the hypothesized profile\n",
    "apt_x = profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extended_threat_profiles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m     ttp_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(t_codes\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m     20\u001b[0m     profile, attackPatterns, relationships \u001b[38;5;241m=\u001b[39m CreateRelationships(ttp_list, aprioriList)\n\u001b[1;32m---> 21\u001b[0m     \u001b[43mextended_threat_profiles\u001b[49m[apt] \u001b[38;5;241m=\u001b[39m profile\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(extended_threat_profiles[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG0025\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'extended_threat_profiles' is not defined"
     ]
    }
   ],
   "source": [
    "# Phase 2: Make APT Threat Profiles\n",
    "attack = Attck()\n",
    "\n",
    "# Dictionary to hold all the threat profiles. \n",
    "# The key is a given APT and the values are a list of TTPs\n",
    "# threat_profiles = {}\n",
    "# threat_profiles = json.load(open(\"datasets/ThreatProfiles/threat_profiles.json\"))\n",
    "for actor in attack.enterprise.actors:\n",
    "    technique_dict = {}\n",
    "    for technique in actor.techniques:\n",
    "        technique_dict[technique.id[0:5]] = 1\n",
    "    threat_profiles[actor.id] = technique_dict\n",
    "    \n",
    "# TODO: Add extended_threat profiles\n",
    "# Create threatprofile Seed -- need to parse the value of the keys.\n",
    "# extended_threat_profiles = {}\n",
    "# extended_threat_profiles = json.load(open(\"datasets/ThreatProfiles/extended_threat_profiles.json\"))\n",
    "for apt, t_codes in threat_profiles.items():\n",
    "    ttp_list = list(t_codes.keys())\n",
    "    profile, attackPatterns, relationships = CreateRelationships(ttp_list, aprioriList)\n",
    "    extended_threat_profiles[apt] = profile\n",
    "\n",
    "print(extended_threat_profiles[\"G0025\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: WEIGHTED JACCARD SIMILARITY\n",
    "# Side note: Find a way to relate techniques and sub-techniques. \n",
    "\n",
    "# TODO: Create a function that compares two threat profiles and produces a Weighted Jaccard. Just returns a number. \n",
    "def weighted_jac (profile1, profile2):\n",
    "\n",
    "    # Extract the keys as sets\n",
    "    keys1 = set(profile1.keys())\n",
    "    keys2 = set(profile2.keys())\n",
    "\n",
    "    # Calculate the Jaccard index\n",
    "    # Only need the normal intersection and union\n",
    "    intersection = keys1.intersection(keys2)\n",
    "    union = keys1.union(keys2)\n",
    "    # jaccard_index = len(intersection) / len(union)\n",
    "\n",
    "    # Weight the Jaccard index by the values in the dictionaries\n",
    "    weighted_intersection = sum(min(profile1[k], profile2[k]) for k in intersection)\n",
    "    weighted_union = sum(max(profile1.get(k, 0), profile2.get(k, 0)) for k in union)\n",
    "    \n",
    "    try:\n",
    "        weighted_jaccard_index = weighted_intersection / weighted_union\n",
    "    except:\n",
    "        print(profile1)\n",
    "        print(profile2)\n",
    "        return 0\n",
    "        \n",
    "    return weighted_jaccard_index\n",
    "    #print(\"Weighted Jaccard index:\", weighted_jaccard_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create another function that calls the previous function on all of the threat profiles and our threat profile of interest.\n",
    "# We could do some sort of ranking like list the APTs with the highest Weighted Jaccard first. \n",
    "def compare_apt(h_threatprofile, threat_profiles):\n",
    "    # Make another dictionary \n",
    "    rankings = {}\n",
    "    \n",
    "    for key, value in threat_profiles.items(): \n",
    "        similarity  = (weighted_jac(value, h_threatprofile)) * 100\n",
    "        percentage = round(similarity, 2)\n",
    "        rankings[key] = percentage\n",
    "    \n",
    "    return rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_apt_dict = compare_apt(apt_x, extended_threat_profiles)\n",
    "\n",
    "# SORTED -- NICE!\n",
    "sorted_dict = dict(sorted(compare_apt_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "print(sorted_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some sort of visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example dictionary\n",
    "data = sorted_dict\n",
    "\n",
    "# Extract keys and values from dictionary\n",
    "labels = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "# Create a bar chart using matplotlib\n",
    "plt.bar(labels, values)\n",
    "\n",
    "# Set chart title and axis labels\n",
    "plt.title('APT THANGS')\n",
    "plt.xlabel('APTs')\n",
    "plt.ylabel('Similarity (%)')\n",
    "\n",
    "# Display the chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the dictionary to a JSON file\n",
    "# import json\n",
    "\n",
    "# with open(\"Extended_Threat_Profiles\", \"w\") as outfile:\n",
    "#     json.dump(extended_threat_profiles, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate heatmap right here\n",
    "# create matrix using pandas dataset with rows and columns being APT groups\n",
    "\n",
    "# some threat groups have no TTPs, we will filter those out\n",
    "\n",
    "heatdf_tgroups = {}\n",
    "for gcode, prof in extended_threat_profiles.items():\n",
    "    if (prof != {}):\n",
    "        heatdf_tgroups[gcode] = prof\n",
    "\n",
    "aptGroups = list(heatdf_tgroups.keys())\n",
    "\n",
    "heatdf = pd.DataFrame(columns=aptGroups)\n",
    "# populate the dataframe\n",
    "for gcode, prof in heatdf_tgroups.items():\n",
    "    for gcode2, prof2 in heatdf_tgroups.items():\n",
    "        simularity = int(weighted_jac(prof, prof2)*100)\n",
    "        heatdf.loc[gcode, gcode2] = simularity\n",
    "\n",
    "heatdf = heatdf.reset_index(drop=True).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Pandas DataFrame to a NumPy array\n",
    "arr = heatdf.to_numpy()\n",
    "\n",
    "# Create a heatmap using the imshow() function\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(arr, cmap='coolwarm')\n",
    "\n",
    "# Add a colorbar to the plot\n",
    "cbar = ax.figure.colorbar(im, ax=ax)\n",
    "\n",
    "# Set the tick labels for the x and y axes\n",
    "ax.set_xticks(np.arange(len(heatdf.columns)))\n",
    "ax.set_yticks(np.arange(len(heatdf.index)))\n",
    "ax.set_xticklabels(heatdf.columns)\n",
    "ax.set_yticklabels(heatdf.index)\n",
    "\n",
    "# Rotate the tick labels on the x axis\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "# set the size of the heatmap\n",
    "fig.set_size_inches(12, 12)\n",
    "\n",
    "# Set the plot title\n",
    "ax.set_title(\"Heatmap of heatdf\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(threat_profiles[\"G0042\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Here we evaluate our models \n",
    "test_set = GenerateTestSet() # this is just G code and associated TTPs, need to make profiles\n",
    "test_profiles = {}\n",
    "#test_profiles = json.load(open(\"datasets/ThreatProfiles/test_profiles.json\"))\n",
    "# create profiles using the test data and make it into a dictionary\n",
    "# we filter data here to remove all empty lists\n",
    "i = 0\n",
    "for gcode, tcodes in (test_set.items()):\n",
    "    i += 1\n",
    "    if (tcodes == ['']):\n",
    "        continue\n",
    "    tcodes = [tc.split('.')[0] if '.' in tc else tc for tc in tcodes]\n",
    "    profile, attackPatterns, relationships = CreateRelationships(tcodes, aprioriList)\n",
    "    \n",
    "    test_profiles[gcode] = profile\n",
    "\n",
    "\n",
    "len(list(test_profiles.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topn: we consider the function a success if the atp group is identified in the top n results.\n",
    "def evaluate_model(topn):\n",
    "    res = [] # 1 for hit and 0 for no hit\n",
    "    conf = []\n",
    "    hits = 0\n",
    "    total = 0\n",
    "    topn = 1\n",
    "    \n",
    "    \n",
    "    for gcode, tcodes in test_profiles.items():\n",
    "            \n",
    "        rankings = Counter(compare_apt(tcodes, extended_threat_profiles)).most_common(topn)\n",
    "        total += 1\n",
    "        lasthit = hits\n",
    "        for k,v in rankings:\n",
    "            if (gcode == k):\n",
    "                conf.append(v)\n",
    "                hits += 1\n",
    "                break\n",
    "        if (lasthit == hits):\n",
    "            res.append(0)\n",
    "        else:\n",
    "            res.append(1)\n",
    "    \n",
    "    print(statistics.mean(conf), statistics.stdev(conf))\n",
    "    sd = statistics.stdev(res)\n",
    "    return((hits/total, sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting data\n",
    "with open(\"datasets/ThreatProfiles/threat_profiles.json\", \"w\") as outfile:\n",
    "    json.dump(threat_profiles, outfile)\n",
    "\n",
    "with open(\"datasets/ThreatProfiles/extended_threat_profiles.json\", \"w\") as outfile:\n",
    "    json.dump(extended_threat_profiles, outfile)\n",
    "\n",
    "with open(\"datasets/ThreatProfiles/test_profiles.json\", \"w\") as outfile:\n",
    "    json.dump(test_profiles, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_query (extended_threat_profiles): \n",
    "    apt_list = []\n",
    "    ttp_list = {}\n",
    "    relationship_list = []\n",
    "    for g_code, t_code_list in extended_threat_profiles.items(): \n",
    "        # Get APTs based on its G-code\n",
    "        apt = src.query([Filter(\"external_references.external_id\", \"=\", g_code)])[0]\n",
    "        apt_list.append(apt)\n",
    "        # Get TTPs based on its T-code\n",
    "        for t_code, confidence in t_code_list.items():\n",
    "            if (not(t_code in ttp_list.keys())):\n",
    "                ttp = src.query([Filter(\"external_references.external_id\", \"=\", t_code)])[0]\n",
    "                ttp_list[t_code] = ttp\n",
    "            conf = float(confidence)*100\n",
    "            conf = str(conf) + '%'\n",
    "            if (confidence > 0.85):\n",
    "                #Create relationships between every TTP and a given APT\n",
    "                relationship = Relationship(apt, conf, ttp_list[t_code])\n",
    "                relationship_list.append(relationship)\n",
    "    \n",
    "    return (apt_list, list(ttp_list.values()), relationship_list)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the lists\n",
    "apt_sdo_list, ttp_sdo_list, relationship_sdo_list = json_query(extended_threat_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_query(extended_threat_profiles)\n",
    "\n",
    "# Print statements to verify that the query worked\n",
    "print(apt_sdo_list[0])\n",
    "print(ttp_sdo_list[0])\n",
    "print(relationship_sdo_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Database Driver Variable\n",
    "uri = \"neo4j+s://ae3c581e.databases.neo4j.io\"\n",
    "user = \"neo4j\"\n",
    "password = \"NIpuTQWR1jR_1EWwpCvZ-eu873ADJznwfrON5WiMwik\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(user, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyCheck(dictionary, key):\n",
    "        if key in dictionary:\n",
    "            return dictionary[key]\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addAPT(apt_sdo_list):\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "        for elem in apt_sdo_list:\n",
    "            query = (\n",
    "                \"CREATE (p1:APT { spec_version: $spec_version, id: $id, created_by_ref: $created_by_ref, created: $created, modified: $modified, name: $name, description: $description, aliases: $aliases, external_references: $external_references}) \"\n",
    "                \"RETURN p1\"\n",
    "            )\n",
    "            result = session.run(query, spec_version = str(elem['spec_version']), id = str(elem['id']), created_by_ref = str(keyCheck(elem, 'created_by_ref')), created = str(keyCheck(elem, 'created')), modified = str(keyCheck(elem, 'modified')), name = str(keyCheck(elem, 'name')), description = str(keyCheck(elem, 'description')), aliases = str(keyCheck(elem, 'aliases')), external_references = str(keyCheck(elem, 'external_references')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addTTP(ttp_sdo_list):\n",
    "        with driver.session(database=\"neo4j\") as session:\n",
    "            for elem in ttp_sdo_list:\n",
    "                query = (\n",
    "                    \"CREATE (p1:TTP { spec_version: $spec_version, id: $id, created_by_ref: $created_by_ref, created: $created, modified: $modified, name: $name, kill_chain_phases: $kill_chain_phases, external_references: $external_references, x_mitre_is_subtechnique: $x_mitre_is_subtechnique}) \"\n",
    "                    \"RETURN p1\"\n",
    "                )\n",
    "                result = session.run(query, spec_version = str(elem['spec_version']), id = str(elem['id']), created_by_ref = str(keyCheck(elem, 'created_by_ref')), created = str(keyCheck(elem, 'created')), modified = str(keyCheck(elem, 'modified')), name = str(keyCheck(elem, 'name')), kill_chain_phases = str(keyCheck(elem, 'kill_chain_phases')), external_references = str(keyCheck(elem, 'external_references')), x_mitre_is_subtechnique = bool(elem['x_mitre_is_subtechnique']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to filter the relationships a little better -- I probably just need to query something in the GUI version\n",
    "# Probably could add something about the realtionship, tbh\n",
    "\n",
    "def addRelationship(relationship_sdo_list):\n",
    "    with driver.session(database=\"neo4j\") as session:\n",
    "            for elem in relationship_sdo_list:\n",
    "                rel_type = elem['relationship_type']\n",
    "                \n",
    "                query = (\n",
    "                    \"MATCH (a1: APT) \"\n",
    "                    \"WHERE a1.id = $sourceId \"\n",
    "                    \"MATCH (aP1: TTP) \"\n",
    "                    \"WHERE aP1.id = $targetId \"\n",
    "                    \"CREATE (a1)-[: USES { id: $id, confidence_level: $relationship_type, description: $description, source_ref: $source_ref, target_ref: $target_ref}]->(aP1) \"\n",
    "                    \"RETURN a1, aP1\"\n",
    "                )\n",
    "\n",
    "                \n",
    "                result = session.run(query, sourceId = elem['source_ref'], targetId = elem['target_ref'], spec_version = str(keyCheck(elem, 'spec_version')), id = str(elem['id']), created_by_ref = str(keyCheck(elem, 'created_by_ref')), created = str(keyCheck(elem, 'created')), modified = str(keyCheck(elem, 'modified')), relationship_type = str(keyCheck(elem, 'relationship_type')), description = keyCheck(elem, 'description'), source_ref = str(keyCheck(elem, 'source_ref')), target_ref = str(keyCheck(elem, 'target_ref')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def buildDatabase(apt_sdo_list, ttp_sdo_list, relationship_sdo_list):\n",
    "    # Add the SDO nodes to the database\n",
    "    addAPT(apt_sdo_list)\n",
    "    addTTP(ttp_sdo_list)\n",
    "    addRelationship(relationship_sdo_list)\n",
    "    driver.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "buildDatabase(apt_sdo_list, ttp_sdo_list, relationship_sdo_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf4546b72c8f221321ebd81cfb6f77ad08fd1107692848c85b98477d65bf1073"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
