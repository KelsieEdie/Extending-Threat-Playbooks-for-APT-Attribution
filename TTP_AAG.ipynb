{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from stix2.v21 import (ThreatActor, Identity, AttackPattern, Campaign, IntrusionSet, Relationship, ExternalReference, Bundle, Grouping)\n",
    "from efficient_apriori import apriori\n",
    "import re\n",
    "from pyattck import Attck\n",
    "import requests\n",
    "from stix2 import MemoryStore, Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings Values - for Apriori Algorithm\n",
    "# TODO - 2: Do we need to adjust these numbers, in order to refine our algorithm metrics??\n",
    "confidenceLevel = 0.70\n",
    "supportLevel = 0.05\n",
    "abstract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateAprioriLists():\n",
    "    # TODO - 2: Do we need to retrain this data on a new dataset? How can we do this?\n",
    "    # Some data comes from this dataset with TTPs\n",
    "    df = pd.read_csv(\"datasets/Categorized_Adversary_TTPs.csv\") # sample dataset of attacks\n",
    "    \n",
    "    # More data is gained by using attck data from tool and malware TTPs\n",
    "    attack = Attck()\n",
    "    \n",
    "    malwares = attack.enterprise.malwares + attack.enterprise.tools\n",
    "    ttpLists = []\n",
    "    for malware in malwares:\n",
    "        ttpLists.append([\"'\" + ttp.id + \"'\" for ttp in malware.techniques])\n",
    "\n",
    "    # To use the apriori we need to generate a list of lists\n",
    "    aprList = ttpLists\n",
    "    for row in df.values:\n",
    "        aprList.append((row[13].strip('][').split(', ')))\n",
    "    return aprList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AbstractTTPs(ttpList):\n",
    "    # Take sub-techniques and remove the .### to abstract them to parent techniques \n",
    "    for i in range(0,len(ttpList)):\n",
    "        ttpList[i] = [re.sub(r'\\.[0-9]+', '', ttp) for ttp in ttpList[i]]\n",
    "    return ttpList "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a list of lists and returns a list of rules sorted by size \n",
    "def AprioriMining(aprList):\n",
    "    # Perform apriori rule association mining\n",
    "    itemsets, rules = apriori(aprList, min_support=supportLevel, min_confidence=confidenceLevel)\n",
    "    \n",
    "    # Sort by size to get the 1:1 mappings first and so on. \n",
    "    ruleNums = np.array([len(rule.lhs+rule.rhs) for rule in rules])\n",
    "    rules = np.array(rules)\n",
    "    inds = ruleNums.argsort()[::]\n",
    "    rules = rules[inds]\n",
    "    \n",
    "    # Maximum rule size of 4 to limit number of rules, any rules with size > 4 are redundant anyways\n",
    "    rules = [x for x in filter(lambda rule: len(rule.lhs+rule.rhs) <= 4, rules)]\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     stix_json \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://raw.githubusercontent.com/mitre-attack/attack-stix-data/master/\u001b[39m\u001b[39m{\u001b[39;00mdomain\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mdomain\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mjson()\n\u001b[1;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m MemoryStore(stix_data\u001b[39m=\u001b[39mstix_json[\u001b[39m\"\u001b[39m\u001b[39mobjects\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m----> 7\u001b[0m src \u001b[39m=\u001b[39m get_data_from_branch(\u001b[39m\"\u001b[39;49m\u001b[39menterprise-attack\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[35], line 5\u001b[0m, in \u001b[0;36mget_data_from_branch\u001b[0;34m(domain)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"get the ATT&CK STIX data from MITRE/CTI. Domain should be 'enterprise-attack', 'mobile-attack' or 'ics-attack'. Branch should typically be master.\"\"\"\u001b[39;00m\n\u001b[1;32m      4\u001b[0m stix_json \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mhttps://raw.githubusercontent.com/mitre-attack/attack-stix-data/master/\u001b[39m\u001b[39m{\u001b[39;00mdomain\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mdomain\u001b[39m}\u001b[39;00m\u001b[39m.json\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mjson()\n\u001b[0;32m----> 5\u001b[0m \u001b[39mreturn\u001b[39;00m MemoryStore(stix_data\u001b[39m=\u001b[39;49mstix_json[\u001b[39m\"\u001b[39;49m\u001b[39mobjects\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/stix2/datastore/memory.py:119\u001b[0m, in \u001b[0;36mMemoryStore.__init__\u001b[0;34m(self, stix_data, allow_custom, version)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data \u001b[39m=\u001b[39m {}\n\u001b[1;32m    118\u001b[0m \u001b[39mif\u001b[39;00m stix_data:\n\u001b[0;32m--> 119\u001b[0m     _add(\u001b[39mself\u001b[39;49m, stix_data, allow_custom, version)\n\u001b[1;32m    121\u001b[0m \u001b[39msuper\u001b[39m(MemoryStore, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m    122\u001b[0m     source\u001b[39m=\u001b[39mMemorySource(stix_data\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data, allow_custom\u001b[39m=\u001b[39mallow_custom, version\u001b[39m=\u001b[39mversion, _store\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m    123\u001b[0m     sink\u001b[39m=\u001b[39mMemorySink(stix_data\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data, allow_custom\u001b[39m=\u001b[39mallow_custom, version\u001b[39m=\u001b[39mversion, _store\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[1;32m    124\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/stix2/datastore/memory.py:35\u001b[0m, in \u001b[0;36m_add\u001b[0;34m(store, stix_data, allow_custom, version)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(stix_data, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     33\u001b[0m     \u001b[39m# STIX objects are in a list- recurse on each object\u001b[39;00m\n\u001b[1;32m     34\u001b[0m     \u001b[39mfor\u001b[39;00m stix_obj \u001b[39min\u001b[39;00m stix_data:\n\u001b[0;32m---> 35\u001b[0m         _add(store, stix_obj, allow_custom, version)\n\u001b[1;32m     37\u001b[0m \u001b[39melif\u001b[39;00m stix_data[\u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbundle\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     38\u001b[0m     \u001b[39m# adding a json bundle - so just grab STIX objects\u001b[39;00m\n\u001b[1;32m     39\u001b[0m     \u001b[39mfor\u001b[39;00m stix_obj \u001b[39min\u001b[39;00m stix_data\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mobjects\u001b[39m\u001b[39m\"\u001b[39m, []):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/stix2/datastore/memory.py:47\u001b[0m, in \u001b[0;36m_add\u001b[0;34m(store, stix_data, allow_custom, version)\u001b[0m\n\u001b[1;32m     45\u001b[0m     stix_obj \u001b[39m=\u001b[39m stix_data\n\u001b[1;32m     46\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 47\u001b[0m     stix_obj \u001b[39m=\u001b[39m parse(stix_data, allow_custom, version)\n\u001b[1;32m     49\u001b[0m \u001b[39m# Map ID to a _ObjectFamily if the object is versioned, so we can track\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m# multiple versions.  Otherwise, map directly to the object.  All\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[39m# versioned objects should have a \"modified\" property.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmodified\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m stix_obj:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/stix2/parsing.py:40\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(data, allow_custom, version)\u001b[0m\n\u001b[1;32m     37\u001b[0m obj \u001b[39m=\u001b[39m _get_dict(data)\n\u001b[1;32m     39\u001b[0m \u001b[39m# convert dict to full python-stix2 obj\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m obj \u001b[39m=\u001b[39m dict_to_stix2(obj, allow_custom, version)\n\u001b[1;32m     42\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/stix2/parsing.py:99\u001b[0m, in \u001b[0;36mdict_to_stix2\u001b[0;34m(stix_dict, allow_custom, version)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[39mreturn\u001b[39;00m stix_dict\n\u001b[1;32m     97\u001b[0m     \u001b[39mraise\u001b[39;00m ParseError(\u001b[39m\"\u001b[39m\u001b[39mCan\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt parse unknown object type \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m! For custom types, use the CustomObject decorator.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m obj_type)\n\u001b[0;32m---> 99\u001b[0m \u001b[39mreturn\u001b[39;00m obj_class(allow_custom\u001b[39m=\u001b[39;49mallow_custom, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mstix_dict)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/stix2/base.py:227\u001b[0m, in \u001b[0;36m_STIXBase.__init__\u001b[0;34m(self, allow_custom, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m             defaulted\u001b[39m.\u001b[39mappend(name)\n\u001b[1;32m    226\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mKeyError\u001b[39;00m):\n\u001b[0;32m--> 227\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_defaulted_optional_properties \u001b[39m=\u001b[39m defaulted\n\u001b[1;32m    230\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner \u001b[39m=\u001b[39m setting_kwargs\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Downloads latest MITRE framework from the branch\n",
    "def get_data_from_branch(domain):\n",
    "    \"\"\"get the ATT&CK STIX data from MITRE/CTI. Domain should be 'enterprise-attack', 'mobile-attack' or 'ics-attack'. Branch should typically be master.\"\"\"\n",
    "    stix_json = requests.get(f\"https://raw.githubusercontent.com/mitre-attack/attack-stix-data/master/{domain}/{domain}.json\").json()\n",
    "    return MemoryStore(stix_data=stix_json[\"objects\"])\n",
    "\n",
    "src = get_data_from_branch(\"enterprise-attack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get TTPs from seed, where seed is an APT group code: GXXXX\n",
    "def ExtractSeedTTPs(seed):\n",
    "    seeds = []\n",
    "    # This runs but says that \"actors\" is not found\n",
    "    actor = actors[seed]\n",
    "    for ttp in actor.techniques:\n",
    "        seeds.append(ttp.id)\n",
    "        \n",
    "    # If we are using abstracted TTPs then remove sub technique\n",
    "    if (abstract):\n",
    "        for i in range(0, len(seeds)):\n",
    "            seeds[i] = re.sub(r'\\.[0-9]+', '', seeds[i])\n",
    "    return seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExportBundle(bundle, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(bundle.serialize())\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each rule has a confidence, lift, support, lhs, rhs, conviction, rule power factor (RPF), \n",
    "\n",
    "# Takes an APTGroup and generates hypothesized relationships and attack pattern objects\n",
    "# Returns a tuple of: (profile, attackPatterns, relationships, groupings)\n",
    "def CreateRelationships(seeds, aprioriLists):\n",
    "    profile = {} #stores the TTP and tactic for easy logging\n",
    "    seen = [] #stores TTPs that have been seen by the algorithm\n",
    "    attackPatterns = [] #stores generated attack pattern objects\n",
    "    relationships = {} # stores generated relationship objects\n",
    "    groupings = {} # stores generated grouping objects\n",
    "\n",
    "    # Get seeds out of the APT group\n",
    "    #seeds = ExtractSeedTTPs(APTGroup)\n",
    "    seeds = [\"T1566\", \"T1204\"]\n",
    "    \n",
    "    # Perform Association Rule Mining\n",
    "    rules = AprioriMining(aprioriLists) \n",
    "    \n",
    "    # Add seeds to activity-attack-graph as nodes\n",
    "    for seed in seeds:\n",
    "        profile[seed] = 1\n",
    "        # Get the stix object for the TTP\n",
    "        ttp = src.query([ Filter(\"external_references.external_id\", \"=\", seed) ])[0]\n",
    "        \n",
    "        # Create and add objects to lists, context is used to identify seeds from hypothesized events\n",
    "        groupings[seed] = (Grouping(object_refs=[ttp.id], context = \"Seed Event\"))\n",
    "        attackPatterns.append(src.query([ Filter(\"external_references.external_id\", \"=\", seed) ])[0])\n",
    "    \n",
    "    seedTotals = [\"'\"+x+\"'\" for x in seeds]\n",
    "    # Use a queue to iterate through and create a tree of TTPs\n",
    "    while len(seeds) > 0:\n",
    "        for rule in rules:\n",
    "            # Check to see if the left hand side of a rule is satisfied \n",
    "            if \"'\"+seeds[0]+\"'\" in rule.lhs and set(rule.lhs).issubset(seedTotals):\n",
    "                # If the lhs is satisfied, then loop through each TTP in the rhs \n",
    "                for ttpName in rule.rhs:\n",
    "                    # If this TTP hasn't been visited already then create STIX objects\n",
    "                    if ttpName not in seen:\n",
    "                        ttp = src.query([ Filter(\"external_references.external_id\", \"=\", ttpName[1:-1]) ])[0]\n",
    "                        \n",
    "                        # rule tactics \n",
    "                        tactics = []\n",
    "                        for i in ttp['kill_chain_phases']:\n",
    "                            tactics.append(i['phase_name'])\n",
    "                        \n",
    "                        # create a new grouping object with the rule name. \n",
    "                        groupings[ttpName[1:-1]] = (Grouping(object_refs=[ttp.id], context = \"Hypothesized Event\"))\n",
    "                        \n",
    "                        attackPatterns.append(ttp)\n",
    "                        seedTotals.append(ttpName)\n",
    "                        seen.append(ttpName)\n",
    "                        seeds.append(ttp['external_references'][0]['external_id'])\n",
    "\n",
    "                    # if the relationship already exists between two objects then we take the one with higher confidence\n",
    "                    # make sure the exact relationship does not alraedy exist\n",
    "                    if not (groupings[seeds[0]]['id'], groupings[ttpName[1:-1]]['id']) in relationships:\n",
    "                        # if the opposite relationship exists then choose the one with the highest confidence to add\n",
    "                        # we do this because if we do not then on the graph there will be two arrows going opposite directions to connect the same 2 TTPs\n",
    "                        # this causes clutter and makes the confidence values unreadable since they will be layered on top of each other\n",
    "                        if (groupings[ttpName[1:-1]]['id'], groupings[seeds[0]]['id']) in relationships:\n",
    "                            # if existing relationship has higher confidence, move on\n",
    "                            if float(relationships[(groupings[ttpName[1:-1]]['id'], groupings[seeds[0]]['id'])]['relationship_type']) > rule.confidence:\n",
    "                                continue # move to next iteration of for loop, so code after this statement won't execute\n",
    "                            # if existing relationship has lower confidence, delete it and let the new relationship take it's place\n",
    "                            else:\n",
    "                                del relationships[(groupings[ttpName[1:-1]]['id'], groupings[seeds[0]]['id'])]\n",
    "                        relationships[(groupings[seeds[0]]['id'], groupings[ttpName[1:-1]]['id'])] = Relationship(groupings[seeds[0]]['id'], str(round(rule.confidence, 3)), groupings[ttpName[1:-1]]['id'])\n",
    "                        profile[ttpName[1:-1]] = round(rule.confidence, 3)\n",
    "        \n",
    "        # pop to progress the queue\n",
    "        seeds.pop(0)\n",
    "\n",
    "    return (profile, attackPatterns, relationships, groupings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprioriList = AbstractTTPs(GenerateAprioriLists()) # generate lists for apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intelSeed = [\"T1566\", \"T1204\"] # Use-case: Observed TTPs\n",
    "profile, attackPatterns, relationships, groupings = CreateRelationships(intelSeed, aprioriList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T1566': 0.836, 'T1204': 0.944, 'T1059': 0.752, 'T1105': 0.74, 'T1027': 0.751, 'T1071': 0.778, 'T1082': 0.819, 'T1547': 0.745, 'T1140': 0.745, 'T1057': 0.753, 'T1083': 0.78, 'T1070': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Displays the results of the Apiori Algorithm \n",
    "print(profile)\n",
    "apt_x = profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bundle STIX Objects for Visualization\n",
    "bundle = Bundle(attackPatterns+list(groupings.values())+list(relationships.values()), allow_custom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export bundle for visualization here: https://github.com/yukh1402/cti-stix-diamond-activity-attack-graph\n",
    "ExportBundle(bundle, \"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T1114': 1, 'T1078': 1, 'T1566': 1, 'T1056': 1, 'T1204': 1, 'T1059': 1, 'T1564': 1, 'T1071': 1, 'T1090': 1}\n",
      "{'T1566': 0.836, 'T1204': 0.944, 'T1059': 0.752, 'T1105': 0.74, 'T1027': 0.751, 'T1071': 0.778, 'T1082': 0.819, 'T1547': 0.745, 'T1140': 0.745, 'T1057': 0.753, 'T1083': 0.78, 'T1070': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Phase 2: Make APT Threat Profiles\n",
    "attack = Attck()\n",
    "\n",
    "# Dictionary to hold all the threat profiles. \n",
    "# The key is a given APT and the values are a list of TTPs\n",
    "threat_profiles = {}\n",
    "\n",
    "for actor in attack.enterprise.actors:\n",
    "    technique_dict = {}\n",
    "    for technique in actor.techniques:\n",
    "        technique_dict[technique.id[0:5]] = 1\n",
    "    threat_profiles[actor.id] = technique_dict\n",
    "    \n",
    "print(threat_profiles[\"G0085\"])\n",
    "\n",
    "\n",
    "# TODO: Add extended_threat profiles\n",
    "# Create threatprofile Seed -- need to parse the value of the keys.\n",
    "extended_threat_profiles = {}\n",
    "for apt, t_codes in threat_profiles.items():\n",
    "    ttp_list = list(t_codes.keys())\n",
    "    profile, attackPatterns, relationships, groupings = CreateRelationships(ttp_list, aprioriList)\n",
    "    extended_threat_profiles[apt] = profile\n",
    "\n",
    "print(extended_threat_profiles[\"G0085\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T1566': 0.836, 'T1204': 0.944, 'T1059': 0.752, 'T1105': 0.74, 'T1027': 0.751, 'T1071': 0.778, 'T1082': 0.819, 'T1547': 0.745, 'T1140': 0.745, 'T1057': 0.753, 'T1083': 0.78, 'T1070': 0.7}\n"
     ]
    }
   ],
   "source": [
    "print(extended_threat_profiles[\"G0085\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted Jaccard index: 0.22018226568216595\n"
     ]
    }
   ],
   "source": [
    "# Phase 2: WEIGHTED JACCARD SIMILARITY\n",
    "# Side note: Find a way to relate techniques and sub-techniques. \n",
    "\n",
    "# TODO: Create a function that compares two threat profiles and produces a Weighted Jaccard. Just returns a number. \n",
    "def weighted_jac (profile1, profile2):\n",
    "\n",
    "    # Extract the keys as sets\n",
    "    keys1 = set(profile1.keys())\n",
    "    keys2 = set(profile2.keys())\n",
    "\n",
    "    # Calculate the Jaccard index\n",
    "    # Only need the normal intersection and union\n",
    "    intersection = keys1.intersection(keys2)\n",
    "    union = keys1.union(keys2)\n",
    "    # jaccard_index = len(intersection) / len(union)\n",
    "\n",
    "    # Weight the Jaccard index by the values in the dictionaries\n",
    "    weighted_intersection = sum(min(profile1[k], profile2[k]) for k in intersection)\n",
    "    weighted_union = sum(max(profile1.get(k, 0), profile2.get(k, 0)) for k in union)\n",
    "    weighted_jaccard_index = weighted_intersection / weighted_union\n",
    "    \n",
    "    print(\"Weighted Jaccard index:\", weighted_jaccard_index)\n",
    "\n",
    "# Will comment all the code below out once the second function is finished.\n",
    "# AAG APT\n",
    "p1 = {'T1566': 0.836, 'T1204': 0.944, 'T1059': 0.752, 'T1105': 0.74, 'T1027': 0.751, 'T1071': 0.778, 'T1082': 0.819, 'T1547': 0.745, 'T1140': 0.745, 'T1057': 0.753, 'T1083': 0.78, 'T1070': 0.7}\n",
    "# Known APT: G0085\n",
    "p2 = {'T1114': 1, 'T1078': 1, 'T1566': 1, 'T1056': 1, 'T1204': 1, 'T1059': 1, 'T1564': 1, 'T1071': 1, 'T1090': 1}\n",
    "\n",
    "weighted_jac(p1, p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create another function that calls the previous function on all of the threat profiles and our threat profile of interest.\n",
    "# We could do some sort of ranking like list the APTs with the highest Weighted Jaccard first. \n",
    "def compare_apt(h_threatprofile, threat_profiles):\n",
    "    \n",
    "    # Make another dictionary \n",
    "    \n",
    "    # for key, value in threat "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf4546b72c8f221321ebd81cfb6f77ad08fd1107692848c85b98477d65bf1073"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
