{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from stix2.v21 import (ThreatActor, Identity, AttackPattern, Campaign, IntrusionSet, Relationship, ExternalReference, Bundle, Grouping)\n",
    "from efficient_apriori import apriori\n",
    "import re\n",
    "from pyattck import Attck\n",
    "import requests\n",
    "from stix2 import MemoryStore, Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings Values - for apriori algorithm\n",
    "confidenceLevel = 0.70\n",
    "supportLevel = 0.05\n",
    "abstract = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateAprioriLists():\n",
    "    # some data comes from this dataset with TTPs\n",
    "    df = pd.read_csv(\"datasets/Categorized_Adversary_TTPs.csv\") # sample dataset of attacks\n",
    "\n",
    "\n",
    "    # more data is gained by using attck data from tool and malware TTPs\n",
    "    attack = Attck()\n",
    "\n",
    "    malwares = attack.enterprise.malwares + attack.enterprise.tools\n",
    "    ttpLists = []\n",
    "    for malware in malwares:\n",
    "        ttpLists.append([\"'\" + ttp.id + \"'\" for ttp in malware.techniques])\n",
    "\n",
    "    # to use the apriori we need to generate a list of lists\n",
    "    aprList = ttpLists\n",
    "    for row in df.values:\n",
    "        aprList.append((row[13].strip('][').split(', ')))\n",
    "    return aprList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AbstractTTPs(ttpList):\n",
    "    # take sub-techniques and remove the .### to abstract them to parent techniques \n",
    "    for i in range(0,len(ttpList)):\n",
    "        ttpList[i] = [re.sub(r'\\.[0-9]+', '', ttp) for ttp in ttpList[i]]\n",
    "    return ttpList "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a list of lists and returns a list of rules sorted by size \n",
    "def AprioriMining(aprList):\n",
    "    # perform apriori rule association mining\n",
    "    itemsets, rules = apriori(aprList, min_support=supportLevel, min_confidence=confidenceLevel)\n",
    "    \n",
    "    # sort by size to get the 1:1 mappings first and so on. \n",
    "    ruleNums = np.array([len(rule.lhs+rule.rhs) for rule in rules])\n",
    "    rules = np.array(rules)\n",
    "    inds = ruleNums.argsort()[::]\n",
    "    rules = rules[inds]\n",
    "    \n",
    "    # maximum rule size of 4 to limit number of rules, any rules with size > 4 are redundant anyways\n",
    "    rules = [x for x in filter(lambda rule: len(rule.lhs+rule.rhs) <= 4, rules)]\n",
    "    return rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloads latest MITRE framework from the branch\n",
    "def get_data_from_branch(domain):\n",
    "    \"\"\"get the ATT&CK STIX data from MITRE/CTI. Domain should be 'enterprise-attack', 'mobile-attack' or 'ics-attack'. Branch should typically be master.\"\"\"\n",
    "    stix_json = requests.get(f\"https://raw.githubusercontent.com/mitre-attack/attack-stix-data/master/{domain}/{domain}.json\").json()\n",
    "    return MemoryStore(stix_data=stix_json[\"objects\"])\n",
    "\n",
    "src = get_data_from_branch(\"enterprise-attack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get TTPs from seed, where seed is an APT group code: GXXXX\n",
    "def ExtractSeedTTPs(seed):\n",
    "    seeds = []\n",
    "    actor = actors[seed]\n",
    "    for ttp in actor.techniques:\n",
    "        seeds.append(ttp.id)\n",
    "        \n",
    "    # if we are using abstracted TTPs then remove sub technique\n",
    "    if (abstract):\n",
    "        for i in range(0, len(seeds)):\n",
    "            seeds[i] = re.sub(r'\\.[0-9]+', '', seeds[i])\n",
    "    return seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExportBundle(bundle, filename):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(bundle.serialize())\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each rule has a confidence, lift, support, lhs, rhs, conviction, rule power factor (RPF), \n",
    "\n",
    "# takes an APTGroup and generates hypothesized relationships and attack pattern objects\n",
    "# returns a tuple of: (profile, attackPatterns, relationships, groupings)\n",
    "def CreateRelationships(seeds, aprioriLists):\n",
    "    profile = {} #stores the TTP and tactic for easy logging\n",
    "    seen = [] #stores TTPs that have been seen by the algorithm\n",
    "    attackPatterns = [] #stores generated attack pattern objects\n",
    "    relationships = {} # stores generated relationship objects\n",
    "    groupings = {} # stores generated grouping objects\n",
    "\n",
    "    \n",
    "    \n",
    "    # get seeds out of the APT group\n",
    "    #seeds = ExtractSeedTTPs(APTGroup)\n",
    "    seeds = [\"T1566\", \"T1204\"]\n",
    "    \n",
    "    # perform association rule mining\n",
    "    rules = AprioriMining(aprioriLists) \n",
    "    \n",
    "    #add seeds to activity-attack-graph as nodes\n",
    "    for seed in seeds:\n",
    "        profile[seed] = 1\n",
    "        # get the stix object for the TTP\n",
    "        ttp = src.query([ Filter(\"external_references.external_id\", \"=\", seed) ])[0]\n",
    "        \n",
    "        # create and add objects to lists, context is used to identify seeds from hypothesized events\n",
    "        groupings[seed] = (Grouping(object_refs=[ttp.id], context = \"Seed Event\"))\n",
    "        attackPatterns.append(src.query([ Filter(\"external_references.external_id\", \"=\", seed) ])[0])\n",
    "    \n",
    "    seedTotals = [\"'\"+x+\"'\" for x in seeds]\n",
    "    # use a queue to iterate through and create a tree of TTPs\n",
    "    while len(seeds) > 0:\n",
    "        for rule in rules:\n",
    "            # check to see if the left hand side of a rule is satisfied \n",
    "            if \"'\"+seeds[0]+\"'\" in rule.lhs and set(rule.lhs).issubset(seedTotals):\n",
    "                #if the lhs is satisfied, then loop through each TTP in the rhs \n",
    "                for ttpName in rule.rhs:\n",
    "                    # if this TTP hasn't been visited already then create STIX objects\n",
    "                    if ttpName not in seen:\n",
    "                        ttp = src.query([ Filter(\"external_references.external_id\", \"=\", ttpName[1:-1]) ])[0]\n",
    "                        \n",
    "                        # rule tactics \n",
    "                        tactics = []\n",
    "                        for i in ttp['kill_chain_phases']:\n",
    "                            tactics.append(i['phase_name'])\n",
    "                        \n",
    "                        # create a new grouping object with the rule name. \n",
    "                        groupings[ttpName[1:-1]] = (Grouping(object_refs=[ttp.id], context = \"Hypothesized Event\"))\n",
    "                        \n",
    "                        \n",
    "\n",
    "                        \n",
    "                        attackPatterns.append(ttp)\n",
    "                        seedTotals.append(ttpName)\n",
    "                        seen.append(ttpName)\n",
    "                        seeds.append(ttp['external_references'][0]['external_id'])\n",
    "\n",
    "                    # if the relationship already exists between two objects then we take the one with higher confidence\n",
    "                    # make sure the exact relationship does not alraedy exist\n",
    "                    if not (groupings[seeds[0]]['id'], groupings[ttpName[1:-1]]['id']) in relationships:\n",
    "                        # if the opposite relationship exists then choose the one with the highest confidence to add\n",
    "                        # we do this because if we do not then on the graph there will be two arrows going opposite directions to connect the same 2 TTPs\n",
    "                        # this causes clutter and makes the confidence values unreadable since they will be layered on top of each other\n",
    "                        if (groupings[ttpName[1:-1]]['id'], groupings[seeds[0]]['id']) in relationships:\n",
    "                            # if existing relationship has higher confidence, move on\n",
    "                            if float(relationships[(groupings[ttpName[1:-1]]['id'], groupings[seeds[0]]['id'])]['relationship_type']) > rule.confidence:\n",
    "                                continue # move to next iteration of for loop, so code after this statement won't execute\n",
    "                            # if existing relationship has lower confidence, delete it and let the new relationship take it's place\n",
    "                            else:\n",
    "                                del relationships[(groupings[ttpName[1:-1]]['id'], groupings[seeds[0]]['id'])]\n",
    "                        relationships[(groupings[seeds[0]]['id'], groupings[ttpName[1:-1]]['id'])] = Relationship(groupings[seeds[0]]['id'], str(round(rule.confidence, 3)), groupings[ttpName[1:-1]]['id'])\n",
    "                        profile[ttpName[1:-1]] = round(rule.confidence, 3)\n",
    "        \n",
    "        # pop to progress the queue\n",
    "        seeds.pop(0)\n",
    "\n",
    "    return (profile, attackPatterns, relationships, groupings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "aprioriList = AbstractTTPs(GenerateAprioriLists()) # generate lists for apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "intelSeed = [\"T1566\", \"T1204\"]\n",
    "profile, attackPatterns, relationships, groupings = CreateRelationships(intelSeed, aprioriList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T1566': 0.836, 'T1204': 0.944, 'T1059': 0.752, 'T1105': 0.74, 'T1027': 0.751, 'T1071': 0.778, 'T1082': 0.819, 'T1547': 0.745, 'T1140': 0.745, 'T1057': 0.753, 'T1083': 0.78, 'T1070': 0.7}\n"
     ]
    }
   ],
   "source": [
    "# Displays the results of the Apiori Algorithm \n",
    "print(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bundle STIX Objects for Visualization\n",
    "bundle = Bundle(attackPatterns+list(groupings.values())+list(relationships.values()), allow_custom=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export bundle for visualization here: https://github.com/yukh1402/cti-stix-diamond-activity-attack-graph\n",
    "ExportBundle(bundle, \"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T1114': 1, 'T1078': 1, 'T1566': 1, 'T1056': 1, 'T1204': 1, 'T1059': 1, 'T1564': 1, 'T1071': 1, 'T1090': 1}\n"
     ]
    }
   ],
   "source": [
    "# Phase 2: Make APT Threat Profiles\n",
    "attack = Attck()\n",
    "\n",
    "# Dictionary to hold all the threat profiles. \n",
    "# The key is a given APT and the values are a list of TTPs\n",
    "threat_profiles = {}\n",
    "\n",
    "for actor in attack.enterprise.actors:\n",
    "    technique_dict = {}\n",
    "    for technique in actor.techniques:\n",
    "        technique_dict[technique.id[0:5]] = 1\n",
    "    threat_profiles[actor.id] = technique_dict\n",
    "    \n",
    "print(threat_profiles[\"G0085\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard index: 0.05\n",
      "Weighted Jaccard index: 0.05\n"
     ]
    }
   ],
   "source": [
    "# Phase 2: JACCARD SIMILARITY\n",
    "# Define the two dictionaries\n",
    "dict1 = {'T1114': 1, 'T1078': 1, 'T1566': 1, 'T1056': 1, 'T1204': 1, 'T1059': 1, 'T1564': 1, 'T1071': 1, 'T1090': 1}\n",
    "dict2 = {'T1114.002': 1, 'T1078': 1, 'T1566.001': 1, 'T1566.002': 1, 'T1056.002': 1, 'T1204.001': 1, 'T1059.005': 1, 'T1204.002': 1, 'T1056.001': 1, 'T1564.008': 1, 'T1071.001': 1, 'T1090.003': 1}\n",
    "\n",
    "# Extract the keys as sets\n",
    "keys1 = set(dict1.keys())\n",
    "keys2 = set(dict2.keys())\n",
    "\n",
    "# Calculate the Jaccard index\n",
    "intersection = keys1.intersection(keys2)\n",
    "union = keys1.union(keys2)\n",
    "jaccard_index = len(intersection) / len(union)\n",
    "\n",
    "# Weight the Jaccard index by the values in the dictionaries\n",
    "weighted_intersection = sum(min(dict1[k], dict2[k]) for k in intersection)\n",
    "weighted_union = sum(max(dict1.get(k, 0), dict2.get(k, 0)) for k in union)\n",
    "weighted_jaccard_index = weighted_intersection / weighted_union\n",
    "\n",
    "# Print the results\n",
    "print(\"Jaccard index:\", jaccard_index)\n",
    "print(\"Weighted Jaccard index:\", weighted_jaccard_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "bf4546b72c8f221321ebd81cfb6f77ad08fd1107692848c85b98477d65bf1073"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
